*** high-priority

initset_object allows creation of a group with same name as a pattern

*** high-priority

update this todo file so that dave can look at it

*** high-priority

think about what needs to be done in order for the wiki to
go live

*** high-priority

move the thresholding logic out of create_thresh_mask so
that it can be used inside convolve_regressors_afni

*** low-priority
warn users that if load_afni_... gives them:
  ??? Error using ==> unknown
  Maximum variable size allowed by the program is exceeded.
that it's probably because of user error
  what are some example causes of this???
    trying to load in a pattern using a mask in anatomical resolution

*** high-priority

improve all check_1ofn messages

*** high-priority
check for afni matlab library updates

*** high-priority
write_to_afni needs to check for whether a pattern has an
associated masked_by field

*** high-priority
in initset_object, check that the masked_by field has been set

*** low-priority
improve and add multi cross_validation script

*** high-priority
backproject script

*** zero-priority
zscoring should be able to deal with rest using an
actives_selname

*** low-priority
deal with the issue of having no training or no testing TRs in an xval
selector in cross-validation (see ConversationVaidehi060118)

  i think i've fixed this???

*** low-priority
get the residuals from a 3dDeconvolve with motion regressors
to get rid of motion

*** low-priority
add section about optional arguments to the manual

*** high-priority
have a sort of similarity structure cross validation
and figure out where search algorithms for voxel weightings should fit in to voxel selection/classification

*** high-priority
rename shift_TRs to shift_timepoints
move convolve_regressors to convolve_regressors_afni

*** low-priority
summarize should display which optional arguments it doesn't
recognise, and advise about optional arguments to get rid of that
warning (maybe)

*** low-priority
ensure that set_mat etc. maintain the single/double type of the
matrix. add options for set_mat, duplicate, init etc.

*** high-priority
add changes to default create_thresh_mask naming

*** low-priority
add optional 'show_test_at_training' argument to cross-validation, and
modify training functions to deal with it

*** documentation
make sure that it mentions the warning in the tutorial
mention that older versions may cause problems

*** low-priority
update scripts that take a long time so they do all their creation of
objects at the beginning rather than the end, in case there's a
problem with the object name
n
*** low-priority
finalize version of anova with runs as a random effect

*** low-priority
figure out how easy it would be to get the clustering thing working

*** low-priority
add echo on for statmap submit jobs
figure out if it's possible to put the parallelisation code at the
feature_select level
when there's an error, display the tail of the relevant .o file to the
screen

*** low-priority
tidy up the internal directory

*** low-priority
make the toolbox deal with both singular and plural forms of the
objtypes

*** low-priority
add documentation re duplicate vs init

*** low-priority
change CheckBrikHead to use error instead of errdlg

*** low-priority
replace all created.function = mfilename with = dbstack

*** low-priority
parallelize cross-validation

*** low-priority
add a 'visibility' flag to all objects to stop things showing up in
the subj structure???

*** low-priority
add 051024 reply to mkc to faqs

*** low-priority
add a find_unlicensed_mvpa release script that checks that all scripts
have the GPL license text included by grepping

*** low-priority
fix summarize noncontig bug

*** low-priority
fix summarize so that it runs a few checks on each object
and also creates a summary struct on a single run through the subj
structure, and then displays based on that

*** low-priority
add check to get_type so that it points out if you erroneously used a
plural

*** low-priority
add associate_pattern_from_hd.m

*** low-priority
get mkc's version of vec2ind

*** low-priority
add cv_args to all train_ functions and documentation

*** low-priority
get rid of rest from tutorial dataset

*** high-priority
work on statmap_3dDeconvolve
add contrasts
test it
see if we can make it simpler
auto-generate its own startpoints
does it deal with censors right???
it should write out its own briks, using write_to_afni
then we need a concatenate briks function to stitch them all together

*** low-priority
incorporate F value anova stuff from MKC (email 051213)


Subj maintenance and accessor scripts
-
*** high-priority
need a way of creating a volume from a pattern. we'll need this if we
want to write 4D patterns-with-time back to AFNI, for instance

*** high-priority
better documentation for optional arguments, custom functions etc.

*** low-priority
propval's a mess. it should take an optional cellORstruct arg, that
defaults to cell. that way it can do proper error-checking with decent
expectations

*** low-priority
add a check so that set_object doesn''t allow you to set the mat

*** low-priority
add a flag so that load_afni_mask can deal with sub-briks

*** low-priority
when you remove an object, it should rename it '_removed', which
get_number will know to check for
refuse to init an object called '_...'

*** high-priority
fix duplicate_object (and any calls to it) so that group_name is a
standard optional parameter

*** low-priority
add functionality for saving subfields when moving to the hard disk
allow moving masks etc. to the hard disk too???

*** low-priority
add to mailing list
    penn people
	 geoff aguirre
	 lyle ungard
	 kahanoids
	 others???
    cmu people
    other people ken emailed me about
    rob schapire
    niam people
    afni people
   

*** low-priority
add new classifiers
add 2-way anova



Importing
-




Preprocessing scripts
-
*** low-priority
is shifting TRs ready to go?
what about convolved regressors

*** low-priority
add checks to zscore so that it looks for single-condition runs

*** low-priority
feature select should be able to take in a cell array of thresholds to
create multiple mask groups



Classification etc.
-
*** high-priority
include CrossEntropy??? did sean write this himself???
fix it

*** high-priority
change documentation to reflect perfmet having scratchpad



Exporting
-
*** high-priority
check write_to_afni




Documentation
-
*** low-priority
bulletin board etc. ideas
	 tortoise svn bug tracking
		  http://tortoisesvn.berlios.de/issues/index.php?do=details&id=156&PHPSESSID=2f7db06257dc8d39ee544667dbf65d52
-
- Our philosophy regarding the removal of TRs, and how it differs
from the philosophy of removing voxels
- Accessing subj structure directly
- classification and results
- see conversation with ken about other docs stuff
- FAQ
- Importing a pattern of arbitrary size without a mask
- Divide by zero from backprop
- Mention when you need the stats toolbox
     mention that prestd might do the same thing as zscore
- Good practices
		   save out as many of the patterns to the hd as
		   possible beforehand
		   lower case
		   split up your BRIKs
- Info about subj.x
- Definitions
	e.g. selectors are discrete, probably exclusive and 1xtimepoints
	stick with the selectors name
- Censoring TRs and dealing with rest
- Conventions
    commenting of m-files
    book-keeping objects, e.g. creation - checklist for developers
    propval argumentations
    incorporate conventions.txt
- Using scripts without using the whole toolbox infrastructure
- More on getting started and setting up work environment
- Running this on your own data
- Things to avoid when designing an experiment
    e.g. diff sizes of conditions, diff sized runs, one condition per run
- How to do event-related
- Solicit requests for future directions
- Extract memory documentation from init_object

*** low-priority
need sample dataset stuff

*** high-priority
Things to talk to Ben Singer about
- Setting up a bulletin board (internal and external)
- Other stuff discussed with CDM and MJB
- SVN permissions
- Adding SVN module for papers
- SVN encrypted passwords
- Adding SVN users
- Bugzilla
- M2HTML
- Wikipedia
- Where are things going to get hosted, contact details etc.
- Quality control
- Logins for outside users

*** low-priority
check documentation for removing voxels???

*** low-priority
add checkout netlab to setup_princeton.htm

*** low-priority
good practices
- don't use a groupname and and objname that are the same
- don't use uppercase

*** low-priority
update the 'removing conditions' section of the documentation

*** low-priority
combine conventions, good practices, errors or howtos???

Testing
-
*** low-priority
try creating a pattern, moving it to the hd while empty, and then
adding to it






Unsorted
-
*** high-priority
add a high-level mvpa.m function so people can type help mvpa???

*** low-priority
tutorial reading recomendations:
Haxby et al.
Start with theoretical overview

*** low-priority
take m2html out of the svn

*** high-priority
add test suite

*** low-priority
add info about saving to the tutorial



Unsorted
-
*** low-priority
check with ziad saad that it's ok to bundle his afni_matlab scripts

*** high-priority
Tests to run
- Check that the appropriate get/set scripts work with 'subj' as
objtype

*** high-priority
look for xxx in the scripts
rename to yyy if they're not crucial to the first release

*** low-priority
look into bugzilla

*** low-priority
add a copyright or website address to all scripts???
what are the contact details for the toolbox???

*** low-priority
tidy up the test_mem functions so that we can refer to them in the
manual in the memory efficiency section

*** high-priority
questions for ronnie/jim/ida
	 why sometimes 5 sometimes 6 rest TRs between conditions
	 which subject???
	 anatomical-only VT mask???
	 what performance were they getting with this???
	 any afni scripts available???
	 shift TRs???
	 what pcrit did they use to define their GLM mask??? is it
	 right that almost all of the voxels pass at 0.05???

*** high-priority
look over BVtoSubj

*** low-priority
convert_pattern_to_4d(subj,patname)

*** low-priority
add functionality to tutorial_haxby for reading in beta weights (that was in AFNItoSubj)

*** low-priority
summarise individual objects






Latest assigned
-
CDM


BDS


GJD


* 0.8 Master ToDo List 

** Move from internal

X  change_objgroup - Change group name of multiple objects
X  confusion
X  multiple_iterations_confusion

X  default_class_args
X  ind2vec_robust
X  intersect_masks
X load_matrix_pattern

  load_bv_pattern (?)
   - /internal/ebc/obsolette/bv_import

X  plot_mds
  
  view_montage (??)

** Keith Schneider for Montage

** Include EBC extension as part of archive

** Run Script

** Update Website









* 0.9 Master Todo

** add regression as optional parameter to cross_validation
(how to distinguish regression)

** basic test for transform_object

** stuff in header?

** Misc

*** Remove add_struct_fields redundancy

** Data Types

*** 'Regressors' --> 'Label'

*** New 'Statmap' Data Type

1. Write paragraph in documentation explaining how it works.
2. Update the tutorial accordingly.
3. Find all places in the code where it needs to be changed.
4. Update feature_select.m and cross_validation.m

*** Core functionality testing suite

** Generic Functions

*** transform_object.m

*** xform_zscore.m
*** xform_detrend.m
*** xform_pca.m
*** xform_dwt_denoise.m
*** xform_savg.m 
Requires working "SPATIAL" Argument

*** transform testing suite

*** create_statmap.m

*** statmap_anova.m
*** statmap_xcorr.m
*** statmap_searchlight.m

*** statmap testing suite


* Major Design / Functionality / Features 

Started by DJW -- these are improvements to land in 0.8

** Generic Functions

We want to separate all actual data processing from MVPA overhead.

_Interfaces:_

*** transform_pattern.m

_Usage:_

[subj] = *transform_pattern*(subj, functname, patname, ...)

Applies a transform to a given pattern in the subject and saves the
result in a new pattern.  Any extra information from the transform is
saved into the *.extra* field of the given pattern.

_Arguments:_

*subj* - the subject structure
*functname* - the name of the transforming function
*patname* - the name of the pattern or group of patterns to transform

_Optional arguments:_

*selname* - (default = none) Apply the transform to the runs specified
by this selector individually, and then concatenate the results.

*runs* - (default = none) Manually specify which of the runs in the
selector to process.  If runs is set, selname must also be set.

*maskname* - (default = none) Apply this mask before running the transform.
If this mask is a group, the transform will be applied multiple times,
creating a group of patterns.  If the pattern is also a group, then
there must be a one-to-one correspondence between patterns and masks
in the group.

*new_patname* - (default = none) The name of the new pattern or stem of
the name of the new pattern group.

*spatial* - (default = false) If true, the second argument to the
transform function is an adjacency list representation of the voxels
in the pattern.  This works even if masks are specified.

*** xform_XXXX.m

_Usage:_

Never called directly.  Passed as an argument to *transform_pattern.m*.

_Arguments:_

The first argument is the matrix of a pattern that will be
transformed.  Rows are voxels and columns are timepoints.  The
first returned value must be the transformed matrix.  *ALL OTHER
PARAMETERS MUST BE OPTIONAL, EXCEPT FOR SPATIAL TRANSFORMS.*

*** Included transform functions:

xform_zscore: Removes linear trends from a pattern.
xform_detrend: Zscores a pattern.
xform_PCA: Re-expresses the pattern in terms of its principal components.
xform_filter: Runs a filter on individual voxel timecourses in the pattern.
xform_dwt_denoise: Performs wavelet-shrinkage based denoising of the pattern.
xform_savg: Performs spatial averaging on the pattern.  *THIS IS A
SPECIAL CASE WHERE SPATIAL TRANSFORM MUST BE SPECIFIED*

*** create_statmap.m:

_Usage:_

[subj] = *create_statmap*(subj, functname, patname, labelsname, selname, ...)

Creates a new statmap object for a given pattern or group of patterns
using a statmap function.  Because these statistics are commonly
supervised (ANOVAs, correlation, etc.), create_statmap requires a
selector name and a labels name and will run only on the training
dataset--unless both labelsname is blank and optional argument 'peeking' is set
to be true.

_Arguments_:

*subj* - MVPA subject structure
*functname* - the name of the statmap_ function to be used.
*patname* - the name of the pattern or group of patterns to use as dataset.
*labelsname* - the name of the labels object for regression analysis. 
*selname* - the name of the selector object which marks test or train runs.

_Optional Arguments_:

*peeking* - (default = false) If true and both labelsname and selname
are equal to '', then runs the statmap function on all TRs of the
pattern.

*new_mapname* - (default = none) Override the automatic naming
convention to specify a name for the new statistical map or stem of
statmap groups.

*maskname* - (default = none) Specify a mask for the dataset pattern.
If *maskname* is a group of patterns, then a group of statmaps are
created.  If patname is also a group, then there must a
one-to-one correspondence between patterns and masks.

*exclude_rest* - (default = true) Whether or not to exclude rest TRs
from the analysis.

*** statmap_XXXX.m

_Usage:_

Never called directly.  Used by create_statmap.  The output must be a
matrix where rows correspond to voxels in the input pattern and
columns correspond to calculated statistics for those voxels.

_Arguments_:

The first argument is the pattern matrix, the second is the labels
matrix, and all other parameters MUST BE OPTIONAL.

*** included statmap_ functions

statmap_anova: run an ANOVA using the labels as regressors and return
the p-value for each voxel.  Requires discrete labels.

statmap_xcorr: calculate correlation coefficient of each voxel with
each label component.

statmap_means: 

statmap_???? (other statmaps in the internal/ directory I don't know
what they do)

** create_custom_mask.m

Create a mask using an anonymous logical function?

** propval improvements

*RETURN A VARARGIN CELL ARRAY THAT CONTAINS THE UNDEFAULTED VALUES!*
THEN THIS CAN BE PASSED TO THE NEXT FUNCTION

** regression

Need to go through trainers and make sure that they can do without the
discrete binary form regressors, or converting to that form easily or something

** data types.

In terms of functionality, distinctions data types seem rather
arbitrary.  This is what I think of as functional groupings:

 - _pattern_: voxels * TRs, NOT A MAPPING                 [nVox x nTRs ]
 - _statmap_: voxels --> statistic                        [pattern #] [nVox]
 - _mask_: voxels --> binary value in R^3                 [X x Y x Z] [nVox]

 - _label_: TRs --> real values (multiple real values?)   [nComp x nTRs]
 - _selector_: TRs --> integer value                      [nValues] [nTRs]

** Summary -  0.8 major features

transform_pattern.m: transforms a pattern using transform function.
xform_zscore: Removes linear trends from a pattern.
xform_detrend: Zscores a pattern.
xform_PCA: Re-expresses the pattern in terms of its principal components.
xform_filter: Runs a filter on individual voxel timecourses in the pattern.
xform_dwt_denoise: Performs wavelet-shrinkage based denoising of the pattern.
xform_savg: Performs spatial averaging on the pattern.  *THIS IS A

create_statmap.m: applies a statmap
statmap_xcorr.m: cross correlation
statmap_anova.m: ANOVA p-values
statmap_searchlight.m: 'searchlight' statmap using moving spheres/boxes
searchlight_malahnois.m: distance metric for searchlight calculations

create_sorted_mask: creates mask from some subset of ranked statmap values
create_thresh_mask: creates mask from thresholded statmap values
create_custom_mask: creates mask from anonymous logical function of statmap values

create_xval_indices: creates cross validation selectors in
  leave-out-one fashion, or arbitrary test/train runs specified by user

feature_select: combines create_statmap and create_XXXX_mask automatically
cross_validation: runs regression/classification for given selectors, etc.
  (optionally now runs prediction on entire dataset)

train_bp, test_bp: backprop classifier/regressor (can't do regression, right?)
train_ridge, test_ridge: ridge regression

train_boost, test_boost: ?? boosting classifier?
train_svm, test_svm: ?? SVM classifier?

new 'statmap' data type -- all basic handlers need to be updated
'regressors' is now 'label' -- all basic handlers need to be updated

bundle: 'bundles' various variables together in a structure for safekeeping
get_pat_and_mask_names: from a pattern name and mask name, returns a cell
  array of names for patterns and masks to be used in one of the
  standard MVPA functions (i.e. takes care of processing groups)
get_adjacency_list: gets the adjacency list for a given pattern (with
  optional mask)

reform_results: convert the original results structure into the fancy form


======================================================================
Substantial Improvements / Functionality / Redesigns
======================================================================

- Parameter searching
- Fixing plurals of object types
- Automated logging/history recording (centralized subject log/audited
  experiment?)
- Propval and optional arguments **

bug?: a lot of the MVPA stuff assumes that regressors is discrete
binary matrix showing conditions, with only one condition active.

- Name of 'Regressors' object -- is 'label', 'response', 'predictee', 

-----------------------
EBC To Do List

Problem: spatial averaging results don't make sense.  PSEARCH_MAT
contradicts ebc_tutorial_adv results.

- across subject averaging boost performance for greg's parameters,
  but not for mine (?)

Potential next steps:

- Incorporate training on blanks, testing on no blanks
- Incorporate Denis' parameters
- Run detrending first?
- Investigate spatial averaging psearch problems...

	
---

    - get basic tutorial up and running - DONE
    - implement: statmap_xcorr.m - DONE
		 perfmet_correlation.m - DONE
		 separate_regressors.m - DONE
		 smooth_predictions.m - DONE
		 train_ridge.m - DONE
		 test_ridge.m - DONE
		 tutorial_ebc_long.m - ALMOST DONE
		 tutorial_ebc_short.m - PRIORITY

    - incorporate Feature_Rater into tutorials - DONE
    - incorporate Denis's parameters - DONE

    - incorporate gstephen's ridge regression - DONE
	 - spatial filtering -
         - temporal filtering - HALF DONE

    - prepare tutorial_ebc1.mat - DONE (subject 1 data)
    - prepare tutorial_ebc2.mat -  DONE 
    - prepare tutorial_ebc3.mat -  DONE 
    - prepare tutorial_ebc_params.mat - DONE
    
    - make sure we are using gstephen's parameters for this - 

    * Testing suite:
      - statmap_xcorr.m tests -   DONE
      - perfmet_correlation.m tests - DONE 
      - separate_regressors.m tests - SORT OF
      - smooth_predictions.m tests -  SORT OF
      - train_ridge.m tests -  DONE
      - test_ridge.m tests -  DONE
      - tutorial_ebc_long.m tests - ALMOST DONE
      - tutorial_ebc_short.m tests -  

	
    - Version 0.1: remaining:

        - remove parameters from tutorial_ebc_*.m - DONE
	- remove smoothing from tutorial_ebc_*.m - DONE
        - remove running the Feature_Rater from ebc_feature_rater.m - DONE

        - clean out internals/ebc directory - DONE
	- check that all .m files have the licensing attached - DONE

	* Documentation
	  - create tutorial_ebc_adv.html 
	  - create tutorial_ebc_intro.html - DONE

        * Test EBC extension package
          - works from scratch on Linux - 
          - works from scratch on OS/X -  DONE
          - works from scratch on Windows -

        - package EBC extension into downloadable file - DONE

	- Publishing:
          - post to EBC message board
          - Put documentation online - DONE

    - Version 0.2:

      - fix ebc_feature_rater.m (scaling) - DONE
      - separate advanced tutorial into modules - DONE
      - add MATLAB's ridge to train_ridge.m - DONE

      - NOTE: I figured out why our statmap_xcorr gives different
        estimates than the offical EBC thing -- this is because their
        critera for selecting blanks uses a for loop, ensuring that no
        period of blanks lasts longer than 6 blocks.  I will redo the
        blanks, using this, I think. - DONE

      - fix statmap_xcorr.m so that using the compiled version is
        optional - DONE

      - optimizations:

      - spatial averaging (pre) ** (4) - DONE
      - temporal averaging (pre) * (5) - DONE
      - temporal averaging (post) - DONE
      - across subject averaging (post) * (6)

      - parameter searching:
	- ridge regression penalty ** (1) - DONE
	- mask size ** (2) - DONE
	- temporal averaging window size **  (3) - DONE

	- matlab/no matlab ridge regression (8) - DONE
	- flags for optimizations (9) - DONE

	** important AND easy

      - update ebc_tutorial_intro.html - DONE
      - create ebc_tutorial_adv.html (??)

      - update data files, and remove tutorial_ebc_params.mat from tar
        - DONE

      - testing: 
	- test_create_spatial_avg_pat.m - DONE
	- test_filter_runs.m

      - bundle documentation in archive -DONE

PRELIMINARY RESULTS:
     - score before spatial filtering: .231 (no blanks)
				       .301 (with blanks)
     - score after spatial filtering:  .212 (no blanks)				      
				       .287 (with blanks)

     - across subject averaging, no blanks: 0.293

-------------------------

	EBC score:
	    greg's params, no blanks, no savg: .203

     - now: .203 no blanks??
    (note: documentation on wiki)

  - Version 0.3:

    - questionable:
      - ebc_tutorial_adv.html?
      - add history for each create_XXX function
      - change separate_regressors to create_row_regs ?

    - mandatory:
        - get performance up to 0.45 or so (somehow)

	

- cross_valdiation.m always says "classification"

-----------------------
Notes:
- note: we are not implementing denis's m1 + m2 correlation ranking
  score thing now.
- note: do we want to allow absolute value of correlation option?

- get htdocs/mvpa running off of svn **

- preprocessing (Denis)

  feature select the voxels w/ correlation

  symFilter.m - boxcar (5 TRs) symmetric --    
  spatial filtering -- makeMASK.m finds neighbors 
		    -- spaceFilter.m performs 

  supervoxels = spatially averaged voxels
	      (best params are for that)

  use the voxel selection from original voxels during regression on
  supervoxels

  note: ridge regression needs scale factor (normalize)

---------------

gstephens: 

 - parameters: second flag is binary flag for spatial filtering (2nd
   submit)
 - 3rd parameter subject averaging 
 - 4th parameter: size of asymmetric time window averaging

 - nVox (topVox) => selecting top voxels based on correlation
   coefficient

 - included blanks
 - correlation coefficients from both movies 


